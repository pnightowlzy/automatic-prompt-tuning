# automatic-prompt-tuning
自动化prompt调优？那是不是不需要上班了，大模型帮我调prompt，然后进行评估再进行优化，难道我真是个天才。


## 基本思路
让模型给人打工，减轻打工人负担。那么我们可以让模型向人去学习。
人在调优Prompt的时候，首先会对这个任务的背景有一定的了解，同时还应具有一些任务常识，例如计算公式，示例等。
写Prompt的过程可以分为一下几步：
1. Instruct： 指导阶段，告诉模型应该做什么。
2. Inmitate: 模仿阶段，让模型模仿我们的examples，few shot。
3. Thinking: 思考阶段，让模型进行思考，需要给出具体的思考步骤，一步一步来，会需要反思是否是正确的。
4. Evaluate: 评估阶段，这一步往往需要人去进行评估，因为机器评估始终还是处于一个unstale的状态。
5. Refine： 优化阶段，对自己写的Prompt进行优化。

明确这五个步骤之后，设计好框架，模型似乎也可以进行Prompt调优了。

## 具体实现
假如我们只有输入和输出，没有这个任务的背景，应该如何去开始第一步呢？
### Learn From Data
答案很简单，learn from data，让模型从数据中学习当前任务的背景，总结出目前应该做的事情，然后给自己一个人设，增加人设可以让模型更好地完成任务。
More efficeient的是human in loop，用户可以自己加入对背景的介绍。

### Template Filling
将背景整理好之后，就可以开始第二步了。
让模型去生成Prompt，最好是能让模型去填充一个模版，这样就可以生成多个基础的prompt。

### Evaluate
评估当前这个Prompt的准确率，所以automatic prompting都要求用户上传数据集，这个评估还是需要从数据集中sample，全评估的话不是特别有必要，因为模型会一直优化，所以评估的样本量应该足够小。

### Refine
在上一步的评估之后，我们可以得到每个Prompt的打分，然后根据打分进行排序，可以根据


